{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO6+Sy9CskVr7oBXABvSo8e",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rabbitmetrics/cx-analytics/blob/main/notebooks/cx-analytics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Link to the data https://cseweb.ucsd.edu/~jmcauley/datasets/amazon_v2/"
      ],
      "metadata": {
        "id": "i3xWnnmM9Zu0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GVUQKzjI9DD6"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import gzip\n",
        "import pandas as pd\n",
        "from urllib.request import urlopen\n",
        "\n",
        "from dotenv import load_dotenv,find_dotenv\n",
        "\n",
        "load_dotenv(find_dotenv())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract data from files\n",
        "data = []\n",
        "with gzip.open('AMAZON_FASHION.json.gz') as f:\n",
        "    for l in f:\n",
        "        data.append(json.loads(l.strip()))\n",
        "        \n",
        "metadata = []\n",
        "with gzip.open('meta_AMAZON_FASHION.json.gz') as f:\n",
        "    for l in f:\n",
        "        metadata.append(json.loads(l.strip()))"
      ],
      "metadata": {
        "id": "xfMx26bI9UYC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the data to dataframes\n",
        "\n",
        "df = pd.DataFrame.from_dict(data)\n",
        "df = df[df['reviewText'].notna()]\n",
        "\n",
        "df_meta=pd.DataFrame.from_dict(metadata)"
      ],
      "metadata": {
        "id": "buRtJKFV9c-D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Truncate the reviewText\n",
        "\n",
        "max_text_length=400\n",
        "def truncate_review(text):\n",
        "    return text[:max_text_length]\n",
        "\n",
        "df['truncated']=df.apply(lambda row: truncate_review(row['reviewText']),axis=1)"
      ],
      "metadata": {
        "id": "MWsFKkQj9g5f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Look for productIds with enough reviews\n",
        "\n",
        "df.groupby('asin').count().sort_values('overall')"
      ],
      "metadata": {
        "id": "kx2Mumm99kRS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Work on only a slice of the dataframe\n",
        "\n",
        "df = df.loc[df['asin'] == 'B000KPIHQ4'].copy()"
      ],
      "metadata": {
        "id": "drJrZ9fA-Bej"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import and apply embeddings from HuggingFace\n",
        "# Warning! Be careful when/if applying embeddings from OpenAI like this - the full review dataframe is more than 800k rows.\n",
        "\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "embeddings = HuggingFaceEmbeddings()\n",
        "\n",
        "df['embeddings']=df.apply(lambda row: embeddings.embed_query(row['truncated']),axis=1)"
      ],
      "metadata": {
        "id": "7rDcZEKx-No4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare training and test sets for training Random Forest Regressor\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    list(df.embeddings.values),\n",
        "    df.overall,\n",
        "    test_size = 0.2,\n",
        "    random_state=1\n",
        ")"
      ],
      "metadata": {
        "id": "NqW4Zg_u-gHd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train and calculate mean absolute error\n",
        "\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "model = RandomForestRegressor(n_estimators=150)\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "mean_absolute_error(y_test, y_pred)"
      ],
      "metadata": {
        "id": "_5X0kZDN-a5q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Pinecone client\n",
        "\n",
        "import pinecone\n",
        "from langchain.vectorstores import Pinecone\n",
        "\n",
        "# Initialize Pinecone\n",
        "pinecone.init(\n",
        "    api_key=os.getenv('PINECONE_API_KEY'),  \n",
        "    environment=os.getenv('PINECONE_ENV')  \n",
        ")"
      ],
      "metadata": {
        "id": "ERZwBLrm_D6D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create list with truncated review texts\n",
        "\n",
        "texts=df['truncated'].tolist()"
      ],
      "metadata": {
        "id": "djRH_VX8_yRB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Send embedding vectors to Pinecone with Langchain\n",
        "\n",
        "vstore = Pinecone.from_texts(texts, embeddings, index_name='cxanalytics')"
      ],
      "metadata": {
        "id": "isuWWKbq_5Ew"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Do a basic vector similarity search\n",
        "\n",
        "query = \"The quality is good\"\n",
        "result = vstore.similarity_search(query)\n",
        "print(result)"
      ],
      "metadata": {
        "id": "v6bdMsFEAM_a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import RetrievalQA adn ChatOpenAPI and define review_chain in order to have GPT-4 access the review data\n",
        "\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "\n",
        "chat = ChatOpenAI(model_name=\"gpt-4\",temperature=0.0)\n",
        "review_chain = RetrievalQA.from_chain_type(llm=chat, chain_type=\"stuff\", retriever=vstore.as_retriever())"
      ],
      "metadata": {
        "id": "l4wke6atAHqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the task for GPT-4 and run the chain\n",
        "\n",
        "q=\"\"\"\n",
        "The reviews you see are for a product called 'Powerstep Pinnacle Orthotic Shoe Insoles'.\n",
        "What is the overall impression of these reviews? Give most prevalent examples in bullets. \n",
        "What do you suggest we focus on improving?\n",
        "\"\"\"\n",
        "\n",
        "result=review_chain.run(q)\n",
        "print(result)"
      ],
      "metadata": {
        "id": "6sneC6j3Aplc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Rename columns in dataframe and create metadatafield in order to do upserts with Pinecone's Python client directly\n",
        "\n",
        "df=df.rename(columns={'embeddings':'values','reviewerID':'id'})\n",
        "df['metadata']=df.apply(lambda row: dict(rating=row['overall']), axis=1)"
      ],
      "metadata": {
        "id": "HQVLN_d-Ashz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create two copies of data, one for the upsert and one for extracting reviewText from ids return from the filtered similarity search\n",
        "\n",
        "data=df[['metadata','values','id']].to_dict(orient='records')\n",
        "data_local=df[['metadata','values','reviewText','id']].to_dict(orient='records')"
      ],
      "metadata": {
        "id": "7RAvagBLBNlf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the Pinecone index\n",
        "\n",
        "pinecone.create_index(name='filtered', metric='euclidean', dimension=768)\n",
        "index = pinecone.Index('filtered')"
      ],
      "metadata": {
        "id": "3XSefD1GBgJb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Upload the data in batches of 50\n",
        "\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "for i in tqdm(range(0, len(data), 50)):\n",
        "    j= i + 50\n",
        "    if j > len(data):\n",
        "        j = len(data)\n",
        "    batch = data[i: j]\n",
        "    index.upsert(vectors=batch)"
      ],
      "metadata": {
        "id": "B0OBFwUiBkc-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run a filtered similarity search\n",
        "\n",
        "query=embeddings.embed_query(\"will buy again\")\n",
        "results = index.query(queries=[query], top_k=100, filter={'rating': {'$eq': 4.0}})\n",
        "print(results)"
      ],
      "metadata": {
        "id": "n6ekNjL8Brcm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the rating from id\n",
        "\n",
        "get_rating_from_id = {\n",
        "    x['id']: {\n",
        "        'rating': x['metadata']['rating'],\n",
        "        'review': x['reviewText'],\n",
        "    } for x in data_local}"
      ],
      "metadata": {
        "id": "4fdaZJGwBx33"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Python function that retrieves reviews matching query and specific rate\n",
        "\n",
        "def review_and_rating(query,rating):\n",
        "    query=embeddings.embed_query(query)\n",
        "    results = index.query(queries=[query], top_k=100, filter={'rating': {'$eq': rating}})\n",
        "    ids = [i['id'] for i in results['results'][0]['matches']]\n",
        "    l=[]\n",
        "    for i in ids:\n",
        "        l.append(get_rating_from_id[i])\n",
        "    return pd.DataFrame(l)"
      ],
      "metadata": {
        "id": "C_30OmFGB8Il"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Repurchase list and winback list\n",
        "\n",
        "repurchase_list=review_and_rating('will purchase again', 5.0)\n",
        "\n",
        "winback=review_and_rating('disappointed', 1.0)\n"
      ],
      "metadata": {
        "id": "C-G8QrlRCKU9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}